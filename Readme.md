# BinEnhance-PRO<br>
üîó This project is a modified version of [BinEnhance](https://github.com/wang-yongpan/BinEnhance).

################################################<br>
**Eval Part**<br>
################################################<br>
**[Eval]** If you just want to evaluate the improvement of BinEnhance-PRO on the seven baselines, you can complete the steps in this section. <br>

1. Install the required environment, the python environment we use is python3.8<br>

```python
pip install -r Requirements.txt
```

2. Download the evaluation dataset from [OneDrive](https://1drv.ms/u/c/229dcb3b4ddd06f8/EWUo-orOTIVAnO6eFqT9ny4BA-G1wcE4h46gWeOeF2nQUQ?e=yktDXC):<br>

   This evaluation dataset contains embeddings of all test binary functions generated by the seven methods used in the paper (HermesSim[^1], TREX[^2], Asteria[^3], Asm2vec[^4], Gemini[^5], Diemph[^6], Codeart[^7]), as well as all embeddings enhanced by BinEnhance-PRO. There are 25 folders after unpacking the evaluation dataset. `Asm2vec‚Äã‚Äã`, `‚Äã‚ÄãAsm2vec+BinEnhance‚Äã‚Äã`, and ‚Äã‚Äã`Asm2vec+BinEnhance-PRO‚Äã‚Äã` represent the embedding files generated by the original method, the BinEnhance, and the BinEnhance-PRO (from the D2_norm dataset), respectively. Other models follow similar naming conventions. `Eval_datas` is the evaluation function pool of different models. `RDFs` are all functions with readable data features. `BinEnhance_models`‚Äã‚Äã and `‚Äã‚ÄãBinEnhance-PRO_models`‚Äã‚Äã are our trained models. <br>

4. Use the storage path of the evaluation dataset downloaded in step 2 to run Eval.py<br>

```python
python eval_pro.py --data-path="xxx/dataset2_Eval"<br>
```

################################################<br>
**Training and Inference Part of BinEnhance-PRO**<br>
################################################<br>
**[Train]** If you want to reproduce the BinEnhance-PRO Framework, you can try it by the following steps.<br>
**[PS:]** The following steps require the IDA Pro tool to extract our eesg, GPUs to train, and other requirements (such as multiprocessing). You may need to modify some settings in some code (such as binary_dir path). If you do not have the above conditions, you can run the Eval part. We have provided the intermediate results. <br>

1. Install the required environment, the python environment we use is python3.8<br>

```python
pip install -r requirements_train.txt
```

2. Node Initial Embedding Generation.<br>

**[Function Node]** After obtaining the function embeddings of baselines, we can run the following function to delete the first '.' in the function name. <br>


```python
def get_unified_funcname(funcname):
    if len(funcname) > 0:
        if '.' == funcname[0]:
            funcname = funcname[1:]
    return funcname
```

And then run whitening_transformation.py to reduce the dimension of embeddings.

```python
python whitening_transformation.py --input-dir xxx --output-dir xxx --dimension xxx

```

**[String Node]** We can run mpnet_generate.py to generate the embeddings of strings after running the IDA scripts (step 3).

```python
python mpnet_generate.py --input-dir xxx --output-dir xxx --dimension xxx --model-path xxx

```

3. EESG construction and SEM train.<br>

We need to modify IDA_script/settings.py and Run IDA python scripts in the IDA_script folder to extract EESG.
```python
python extract.py --process-num 30 --output-dir xxx

```

Then, we need to split our EESG files, function embeddings, and string embeddings to train, valid, and test (8:1:1). After this, modify the corresponding path (eesg, function embeddings and string embeddings of each class) in train.py. Finally, run train.py the train our SEM model.


```python
python train_pro.py --base-path xxx --model-save xxx --fis HermesSim --name dataset2 
```

4. Eval.<br>

See the Eval part.

################################################<br>
**Datasets in our paper**<br>
################################################<br>

**D2_norm and D2_noinline in the paper (The homologous function pairs for the evaluation of the function inline scenario can be constructed from them)**: These datasets can download from [normal_dataset](https://drive.google.com/file/d/1K9ef-OoRBr0X5u8g2mlnYqh9o1i6zFij/view) and [noinline_dataset](https://drive.google.com/file/d/1wt7GY-DDp8J_2zeBBVUrcfWIyerg_xLO/view) in [Binkit](https://github.com/SoftSec-KAIST/BinKit).<br>


################################################<br>
**References**<br>
################################################<br>

[^1]: H. He, X. Lin, Z. Weng, R. Zhao, S. Gan, L. Chen, Y. Ji, J. Wang, and Z. Xue, ‚ÄúCode is not natural language: Unlock the power of semantics oriented graph representation for binary code similarity detection,‚Äù in 33rd USENIX Security Symposium (USENIX Security 24), PHILADELPHIA, PA, 2024. 
[^2]: K. Pei, Z. Xuan, J. Yang, S. Jana, and B. Ray, ‚ÄúLearning approximate execution semantics from traces for binary function similarity,‚Äù IEEE Transactions on Software Engineering, vol. 49, no. 4, pp. 2776‚Äì2790, 2022.
[^3]: S. Yang, L. Cheng, Y. Zeng, Z. Lang, H. Zhu, and Z. Shi, ‚ÄúAsteria: Deep learning-based ast-encoding for cross-platform binary code similarity detection,‚Äù in 2021 51st Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN). IEEE, 2021, pp. 224‚Äì236.
[^4]: S. H. Ding, B. C. Fung, and P. Charland, ‚ÄúAsm2vec: Boosting static representation robustness for binary clone search against code obfuscation and compiler optimization,‚Äù in 2019 IEEE Symposium on Security and Privacy (SP). IEEE, 2019, pp. 472‚Äì489. 
[^5]: X. Xu, C. Liu, Q. Feng, H. Yin, L. Song, and D. Song, ‚ÄúNeural network based graph embedding for cross-platform binary code similarity detection,‚Äù in Proceedings of the 2017 ACM SIGSAC conference on computer and communications security, 2017, pp. 363‚Äì376. 
[^6]: Xu X, Feng S, Ye Y, et al. Improving binary code similarity transformer models by semantics-driven instruction deemphasis[C]//Proceedings of the 32nd ACM SIGSOFT International Symposium on Software Testing and Analysis. 2023: 1106-1118.
[^7]: Su Z, Xu X, Huang Z, et al. Codeart: Better code models by attention regularization when symbols are lacking[J]. Proceedings of the ACM on Software Engineering, 2024, 1(FSE): 562-585.


